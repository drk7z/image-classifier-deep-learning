{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data availability\n",
    "train_dir = data_dir / 'train'\n",
    "val_dir = data_dir / 'validation'\n",
    "test_dir = data_dir / 'test'\n",
    "\n",
    "print(\"üìä Dataset Summary:\")\n",
    "print(f\"Train directory: {train_dir} - Exists: {train_dir.exists()}\")\n",
    "print(f\"Validation directory: {val_dir} - Exists: {val_dir.exists()}\")\n",
    "print(f\"Test directory: {test_dir} - Exists: {test_dir.exists()}\")\n",
    "\n",
    "# Count images if directories exist\n",
    "def count_images_in_dir(directory):\n",
    "    \"\"\"Count images in directory and subdirectories\"\"\"\n",
    "    if not directory.exists():\n",
    "        return 0\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        count += len([f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    return count\n",
    "\n",
    "if train_dir.exists():\n",
    "    train_count = count_images_in_dir(train_dir)\n",
    "    val_count = count_images_in_dir(val_dir)\n",
    "    test_count = count_images_in_dir(test_dir)\n",
    "    \n",
    "    print(f\"\\nüìà Image Counts:\")\n",
    "    print(f\"Training images: {train_count}\")\n",
    "    print(f\"Validation images: {val_count}\")\n",
    "    print(f\"Test images: {test_count}\")\n",
    "    print(f\"Total: {train_count + val_count + test_count}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Dataset not found. Please download and organize the Cats vs Dogs dataset.\")\n",
    "    print(\"Expected structure:\")\n",
    "    print(\"data/\")\n",
    "    print(\"‚îú‚îÄ‚îÄ train/\")\n",
    "    print(\"‚îÇ   ‚îú‚îÄ‚îÄ cats/\")\n",
    "    print(\"‚îÇ   ‚îî‚îÄ‚îÄ dogs/\")\n",
    "    print(\"‚îú‚îÄ‚îÄ validation/\")\n",
    "    print(\"‚îÇ   ‚îú‚îÄ‚îÄ cats/\")\n",
    "    print(\"‚îÇ   ‚îî‚îÄ‚îÄ dogs/\")\n",
    "    print(\"‚îî‚îÄ‚îÄ test/\")\n",
    "    print(\"    ‚îú‚îÄ‚îÄ cats/\")\n",
    "    print(\"    ‚îî‚îÄ‚îÄ dogs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e394101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Microsoft Cats vs Dogs dataset\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# Create data directory\n",
    "data_dir = Path('../data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Download dataset (note: this is a large file ~786MB)\n",
    "print(\"‚è≥ Downloading Cats vs Dogs dataset...\")\n",
    "url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
    "\n",
    "# Alternative: Use smaller sample or local files\n",
    "# For demonstration, we'll assume data is already organized\n",
    "print(\"üìÅ Data directory structure:\")\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    level = root.replace(str(data_dir), '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:3]:  # Show only first 3 files\n",
    "        print(f'{subindent}{file}')\n",
    "    if len(files) > 3:\n",
    "        print(f'{subindent}... and {len(files) - 3} more files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a068a",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load and Explore Dataset\n",
    "\n",
    "### Download and Prepare Data\n",
    "For this example, we'll use the Microsoft Cats vs Dogs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90286e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics and evaluation\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150c924",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70b5cf",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Image Classifier com Deep Learning\n",
    "## Classifica√ß√£o de Gatos vs C√£es usando CNN\n",
    "\n",
    "Este notebook implementa um classificador de imagens usando Redes Neurais Convolucionais (CNN) com TensorFlow/Keras.\n",
    "\n",
    "### üìä Objetivos\n",
    "- ‚úÖ Manipula√ß√£o e preprocessamento de imagens\n",
    "- ‚úÖ Data Augmentation para melhorar robustez\n",
    "- ‚úÖ Constru√ß√£o de CNN personalizada\n",
    "- ‚úÖ Treinamento com monitoramento de overfitting\n",
    "- ‚úÖ Avalia√ß√£o com m√©tricas diversas\n",
    "- ‚úÖ Compara√ß√£o com Transfer Learning"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
