{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c254be81",
   "metadata": {},
   "source": [
    "## üìù Conclus√µes e Insights\n",
    "\n",
    "### üéØ Resultados Alcan√ßados\n",
    "1. **Modelo CNN Personalizado**: Treinado do zero com data augmentation\n",
    "2. **Transfer Learning**: Aproveitamento de pesos pr√©-treinados do ImageNet  \n",
    "3. **M√©tricas Completas**: Accuracy, Precision, Recall, Confusion Matrix, ROC-AUC\n",
    "\n",
    "### üí° Pontos-Chave\n",
    "- Transfer Learning geralmente apresenta melhor desempenho com menos dados\n",
    "- Data Augmentation √© essencial para evitar overfitting\n",
    "- Batch Normalization estabiliza o treinamento\n",
    "- Early Stopping previne overfitting\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos\n",
    "- [ ] Fine-tuning do modelo pr√©-treinado\n",
    "- [ ] Testar com outras arquiteturas (ResNet, EfficientNet)\n",
    "- [ ] Deploy da aplica√ß√£o com Gradio/FastAPI\n",
    "- [ ] Implementar explicabilidade (Grad-CAM)\n",
    "- [ ] Testar em produ√ß√£o com dados reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baee9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both models\n",
    "if test_dir.exists():\n",
    "    print(\"üìä Comparing CNN vs Transfer Learning Models\\n\")\n",
    "    \n",
    "    # Evaluate custom CNN\n",
    "    test_loss_cnn, test_acc_cnn, _, _ = model.evaluate(test_generator, verbose=0)\n",
    "    \n",
    "    # Evaluate transfer learning\n",
    "    test_loss_tl, test_acc_tl = model_tl.evaluate(test_generator, verbose=0)\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Model': ['Custom CNN', 'Transfer Learning (MobileNetV2)'],\n",
    "        'Test Loss': [f'{test_loss_cnn:.4f}', f'{test_loss_tl:.4f}'],\n",
    "        'Test Accuracy': [f'{test_acc_cnn:.4f} ({test_acc_cnn*100:.2f}%)', \n",
    "                         f'{test_acc_tl:.4f} ({test_acc_tl*100:.2f}%)'],\n",
    "        'Parameters': [f'{model.count_params():,}', f'{model_tl.count_params():,}']\n",
    "    })\n",
    "    \n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    models_names = ['Custom CNN', 'Transfer Learning']\n",
    "    accuracies = [test_acc_cnn*100, test_acc_tl*100]\n",
    "    losses = [test_loss_cnn, test_loss_tl]\n",
    "    \n",
    "    colors = ['#FF6B6B', '#4ECDC4']\n",
    "    \n",
    "    axes[0].bar(models_names, accuracies, color=colors)\n",
    "    axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[0].set_title('Model Accuracy Comparison', fontweight='bold')\n",
    "    axes[0].set_ylim([0, 100])\n",
    "    for i, v in enumerate(accuracies):\n",
    "        axes[0].text(i, v+2, f'{v:.2f}%', ha='center', fontweight='bold')\n",
    "    \n",
    "    axes[1].bar(models_names, losses, color=colors)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].set_title('Model Loss Comparison', fontweight='bold')\n",
    "    for i, v in enumerate(losses):\n",
    "        axes[1].text(i, v+0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca975f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train transfer learning model\n",
    "if train_dir.exists():\n",
    "    print(\"üöÄ Training Transfer Learning Model...\")\n",
    "    \n",
    "    # Use same callbacks\n",
    "    callbacks_tl = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0),\n",
    "        ModelCheckpoint(f'../models/transfer_learning_{timestamp}.h5', \n",
    "                       monitor='val_accuracy', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    history_tl = model_tl.fit(\n",
    "        train_generator,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks_tl,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Transfer Learning training complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Transfer Learning model using MobileNetV2\n",
    "def create_transfer_learning_model(num_classes=2):\n",
    "    \"\"\"\n",
    "    Create transfer learning model using MobileNetV2\n",
    "    \"\"\"\n",
    "    # Load pre-trained MobileNetV2\n",
    "    base_model = keras.applications.MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Create new model\n",
    "    model_tl = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model_tl\n",
    "\n",
    "# Create and compile transfer learning model\n",
    "print(\"üîÑ Creating Transfer Learning Model (MobileNetV2)...\")\n",
    "model_tl = create_transfer_learning_model()\n",
    "\n",
    "model_tl.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Transfer Learning model created!\")\n",
    "print(f\"Total parameters: {model_tl.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in model_tl.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3a093",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Transfer Learning: Compara√ß√£o com MobileNetV2\n",
    "\n",
    "Implementando Transfer Learning usando um modelo pr√©-treinado para compara√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on single image\n",
    "def predict_image(image_path, class_names=['cat', 'dog']):\n",
    "    \"\"\"Predict class for a single image\"\"\"\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_array = np.array(img.resize((IMG_SIZE, IMG_SIZE))) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    pred_idx = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][pred_idx]\n",
    "    \n",
    "    return class_names[pred_idx], confidence, predictions[0]\n",
    "\n",
    "# Test on sample images\n",
    "if test_dir.exists():\n",
    "    test_images = []\n",
    "    for class_dir in (test_dir / 'cats').iterdir():\n",
    "        if class_dir.is_file():\n",
    "            test_images.append(class_dir)\n",
    "            break\n",
    "    \n",
    "    for class_dir in (test_dir / 'dogs').iterdir():\n",
    "        if class_dir.is_file():\n",
    "            test_images.append(class_dir)\n",
    "            break\n",
    "    \n",
    "    if test_images:\n",
    "        fig, axes = plt.subplots(1, len(test_images), figsize=(12, 5))\n",
    "        if len(test_images) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, img_path in enumerate(test_images):\n",
    "            pred_class, confidence, all_preds = predict_image(img_path)\n",
    "            \n",
    "            img = Image.open(img_path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(f'Prediction: {pred_class.upper()}\\nConfidence: {confidence:.2%}',\n",
    "                              fontweight='bold', fontsize=11)\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9033c",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Make Predictions on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC Curves\n",
    "if test_dir.exists():\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    \n",
    "    # One-hot encode true labels\n",
    "    true_labels_onehot = label_binarize(true_labels, classes=range(len(class_names)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for i in range(len(class_names)):\n",
    "        fpr, tpr, _ = roc_curve(true_labels_onehot[:, i], predictions[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=f'{class_names[i]} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curves - Test Set', fontweight='bold', fontsize=14)\n",
    "    plt.legend(loc='lower right', fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35670ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and create confusion matrix\n",
    "if test_dir.exists():\n",
    "    predictions = model.predict(test_generator)\n",
    "    pred_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = test_generator.classes\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    \n",
    "    # Classification report\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "    report = classification_report(true_labels, pred_labels, target_names=class_names)\n",
    "    \n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=class_names,\n",
    "               yticklabels=class_names,\n",
    "               cbar_kws={'label': 'Count'})\n",
    "    plt.title('Confusion Matrix - Test Set', fontweight='bold', fontsize=14)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe50834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "if test_dir.exists():\n",
    "    test_generator = val_test_datagen.flow_from_directory(\n",
    "        str(test_dir),\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(\"üìä Evaluating on test set...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n",
    "    \n",
    "    print(\"\\n‚úÖ Test Set Metrics:\")\n",
    "    print(f\"  Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    print(f\"  Precision: {test_precision:.4f}\")\n",
    "    print(f\"  Recall: {test_recall:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No test data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79a9d0",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "if 'history' in locals():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy', fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].set_title('Model Loss', fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].plot(history.history['precision'], label='Train', linewidth=2)\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].set_title('Model Precision', fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].plot(history.history['recall'], label='Train', linewidth=2)\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Validation', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].set_title('Model Recall', fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "if train_dir.exists():\n",
    "    print(\"üöÄ Starting training...\")\n",
    "    print(f\"Timestamp: {timestamp}\")\n",
    "    \n",
    "    # Create data generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        str(train_dir),\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_test_datagen.flow_from_directory(\n",
    "        str(val_dir),\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nClasses: {train_generator.class_indices}\")\n",
    "    print(f\"Training samples: ~{len(train_generator) * BATCH_SIZE}\")\n",
    "    print(f\"Validation samples: ~{len(validation_generator) * BATCH_SIZE}\")\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        validation_steps=len(validation_generator)\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Training complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No training data found. Skipping training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        f'../models/cnn_classifier_{timestamp}.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=f'../logs/{timestamp}',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Callbacks configured!\")\n",
    "print(\"- EarlyStopping: patience=10\")\n",
    "print(\"- ModelCheckpoint: Save best model\")\n",
    "print(\"- ReduceLROnPlateau: Reduce LR if val_loss plateaus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model compiled!\")\n",
    "print(f\"Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"Loss: Categorical Crossentropy\")\n",
    "print(f\"Metrics: Accuracy, Precision, Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a6b869",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model architecture\n",
    "def create_cnn_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=2):\n",
    "    \"\"\"\n",
    "    Create a custom CNN model for image classification\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Block 1\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', \n",
    "                     input_shape=input_shape, name='conv1_1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), name='pool3'),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 4\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), name='pool4'),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        layers.Dense(512, activation='relu', name='fc1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(256, activation='relu', name='fc2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Output Layer\n",
    "        layers.Dense(num_classes, activation='softmax', name='output')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Display model architecture\n",
    "print(\"üß† Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Plot model architecture\n",
    "from tensorflow.keras.utils import plot_model\n",
    "try:\n",
    "    plot_model(model, to_file='model_architecture.png', show_shapes=True)\n",
    "    print(\"‚úÖ Model architecture saved to 'model_architecture.png'\")\n",
    "except:\n",
    "    print(\"visualization library not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31539b15",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Build CNN Model Architecture\n",
    "\n",
    "Construindo uma CNN com:\n",
    "- 4 blocos convolucionais (32, 64, 128, 256 filtros)\n",
    "- Batch Normalization para estabilidade\n",
    "- MaxPooling para reduzir dimensionalidade\n",
    "- Dropout para prevenir overfitting\n",
    "- Camadas totalmente conectadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4669c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure image size and batch size\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create data generators with augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Just rescaling for validation and test\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"‚úÖ Data generators created!\")\n",
    "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Show augmentation examples\n",
    "if train_dir.exists():\n",
    "    # Get sample image\n",
    "    sample_cat = list((train_dir / 'cats').glob('*.jpg'))[0]\n",
    "    sample_img = load_img(sample_cat, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    # Plot augmented versions\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        if i == 0:\n",
    "            ax.imshow(sample_img)\n",
    "            ax.set_title('Original', fontweight='bold')\n",
    "        else:\n",
    "            # Generate augmented image\n",
    "            augmented_img = train_datagen.random_transform(np.array(sample_img))\n",
    "            augmented_img = np.clip(augmented_img, 0, 255).astype(np.uint8)\n",
    "            ax.imshow(augmented_img)\n",
    "            ax.set_title(f'Augmented {i}', fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f8c49",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Data Preprocessing and Augmentation\n",
    "\n",
    "### Caracter√≠sticas das imagens\n",
    "- Redimensionamento: 224x224 pixels (padr√£o ResNet)\n",
    "- Normaliza√ß√£o: Valores de pixel entre 0-1\n",
    "- Augmenta√ß√£o: Rota√ß√£o, flip, zoom, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def visualize_sample_images(data_dir, num_images=4):\n",
    "    \"\"\"Visualize sample images from dataset\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    train_cat_dir = data_dir / 'train' / 'cats'\n",
    "    train_dog_dir = data_dir / 'train' / 'dogs'\n",
    "    \n",
    "    if train_cat_dir.exists() and train_dog_dir.exists():\n",
    "        cat_images = list(train_cat_dir.glob('*.jpg')) + list(train_cat_dir.glob('*.png'))\n",
    "        dog_images = list(train_dog_dir.glob('*.jpg')) + list(train_dog_dir.glob('*.png'))\n",
    "        \n",
    "        # Show cats\n",
    "        for i in range(2):\n",
    "            if i < len(cat_images):\n",
    "                img = Image.open(cat_images[i])\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title('Cat', fontsize=12, fontweight='bold')\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # Show dogs\n",
    "        for i in range(2):\n",
    "            if i < len(dog_images):\n",
    "                img = Image.open(dog_images[i])\n",
    "                axes[2+i].imshow(img)\n",
    "                axes[2+i].set_title('Dog', fontsize=12, fontweight='bold')\n",
    "                axes[2+i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call visualization if data exists\n",
    "if train_dir.exists():\n",
    "    visualize_sample_images(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data availability\n",
    "train_dir = data_dir / 'train'\n",
    "val_dir = data_dir / 'validation'\n",
    "test_dir = data_dir / 'test'\n",
    "\n",
    "print(\"üìä Dataset Summary:\")\n",
    "print(f\"Train directory: {train_dir} - Exists: {train_dir.exists()}\")\n",
    "print(f\"Validation directory: {val_dir} - Exists: {val_dir.exists()}\")\n",
    "print(f\"Test directory: {test_dir} - Exists: {test_dir.exists()}\")\n",
    "\n",
    "# Count images if directories exist\n",
    "def count_images_in_dir(directory):\n",
    "    \"\"\"Count images in directory and subdirectories\"\"\"\n",
    "    if not directory.exists():\n",
    "        return 0\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        count += len([f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    return count\n",
    "\n",
    "if train_dir.exists():\n",
    "    train_count = count_images_in_dir(train_dir)\n",
    "    val_count = count_images_in_dir(val_dir)\n",
    "    test_count = count_images_in_dir(test_dir)\n",
    "    \n",
    "    print(f\"\\nüìà Image Counts:\")\n",
    "    print(f\"Training images: {train_count}\")\n",
    "    print(f\"Validation images: {val_count}\")\n",
    "    print(f\"Test images: {test_count}\")\n",
    "    print(f\"Total: {train_count + val_count + test_count}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Dataset not found. Please download and organize the Cats vs Dogs dataset.\")\n",
    "    print(\"Expected structure:\")\n",
    "    print(\"data/\")\n",
    "    print(\"‚îú‚îÄ‚îÄ train/\")\n",
    "    print(\"‚îÇ   ‚îú‚îÄ‚îÄ cats/\")\n",
    "    print(\"‚îÇ   ‚îî‚îÄ‚îÄ dogs/\")\n",
    "    print(\"‚îú‚îÄ‚îÄ validation/\")\n",
    "    print(\"‚îÇ   ‚îú‚îÄ‚îÄ cats/\")\n",
    "    print(\"‚îÇ   ‚îî‚îÄ‚îÄ dogs/\")\n",
    "    print(\"‚îî‚îÄ‚îÄ test/\")\n",
    "    print(\"    ‚îú‚îÄ‚îÄ cats/\")\n",
    "    print(\"    ‚îî‚îÄ‚îÄ dogs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e394101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Microsoft Cats vs Dogs dataset\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# Create data directory\n",
    "data_dir = Path('../data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Download dataset (note: this is a large file ~786MB)\n",
    "print(\"‚è≥ Downloading Cats vs Dogs dataset...\")\n",
    "url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
    "\n",
    "# Alternative: Use smaller sample or local files\n",
    "# For demonstration, we'll assume data is already organized\n",
    "print(\"üìÅ Data directory structure:\")\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    level = root.replace(str(data_dir), '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:3]:  # Show only first 3 files\n",
    "        print(f'{subindent}{file}')\n",
    "    if len(files) > 3:\n",
    "        print(f'{subindent}... and {len(files) - 3} more files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a068a",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load and Explore Dataset\n",
    "\n",
    "### Download and Prepare Data\n",
    "For this example, we'll use the Microsoft Cats vs Dogs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90286e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics and evaluation\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150c924",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70b5cf",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Image Classifier com Deep Learning\n",
    "## Classifica√ß√£o de Gatos vs C√£es usando CNN\n",
    "\n",
    "Este notebook implementa um classificador de imagens usando Redes Neurais Convolucionais (CNN) com TensorFlow/Keras.\n",
    "\n",
    "### üìä Objetivos\n",
    "- ‚úÖ Manipula√ß√£o e preprocessamento de imagens\n",
    "- ‚úÖ Data Augmentation para melhorar robustez\n",
    "- ‚úÖ Constru√ß√£o de CNN personalizada\n",
    "- ‚úÖ Treinamento com monitoramento de overfitting\n",
    "- ‚úÖ Avalia√ß√£o com m√©tricas diversas\n",
    "- ‚úÖ Compara√ß√£o com Transfer Learning"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
